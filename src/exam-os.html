<!DOCTYPE html>
<html lang="it">
  <head>
    <meta charset="UTF-8" />
    <title>Esercizi - Sistemi Operativi</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <style>
      body {
        font-family: Arial, sans-serif;
        margin: 2rem;
        background-color: #f9f9f9;
      }
      h1 {
        color: #2c3e50;
        margin-bottom: 2rem;
      }
      #esercizi-list {
        max-width: 800px;
        margin: 0 auto;
      }
      .esercizio-card {
        background: #fff;
        border-left: 5px solid #3498db;
        box-shadow: 0 0 5px rgba(0, 0, 0, 0.1);
        margin-bottom: 1rem;
        padding: 0;
        border-radius: 6px;
        overflow: hidden;
      }
      .esercizio-header {
        cursor: pointer;
        padding: 1rem;
        font-weight: bold;
        background: #eaf6fb;
        display: flex;
        justify-content: space-between;
        align-items: center;
        outline: none;
      }
      .esercizio-header:focus {
        box-shadow: 0 0 0 2px #3498db;
      }
      .arrow {
        font-size: 1.2em;
        transition: transform 0.2s;
      }
      .esercizio-content {
        padding: 1rem;
        border-top: 1px solid #eee;
        display: none;
      }
      .domanda {
        font-weight: bold;
        margin-bottom: 0.5rem;
      }
      .risposta {
        color: #27ae60;
        font-weight: bold;
        margin-bottom: 0.5rem;
      }
      .spiegazione {
        margin-top: 0.5rem;
      }
    </style>
  </head>
  <body>
    <h1>Esercizi Sistemi Operativi</h1>
    <label
      for="scheda-select"
      style="font-weight: bold; margin-bottom: 1rem; display: block"
      >Scegli scheda:</label
    >
    <select id="scheda-select" style="margin-bottom: 2rem">
      <option value="gennaio-inglese">Gennaio 2025 [EN]</option>
      <option value="gennaio-2025-it">Gennaio 2025 [IT]</option>
      <option value="settembre-2024">Settembre 2024</option>
      <option value="giugno-2024">Giugno 2024</option>
      <option value="giugno-2025">Giugno 2025</option>
      <option value="luglio-2016">Luglio 2016</option>
    </select>
    <div id="esercizi-list"></div>
    <noscript>
      <p>
        Abilita JavaScript per visualizzare gli esercizi in modo interattivo.
      </p>
    </noscript>
    <script>
      const eserciziGiugno2025 = [
        {
          domanda:
            "Calcolare il TLB hit minimo necessario per ottenere un EAT al più del 40% superiore al tempo RAM (TRAM = 40 ns) in un sistema con TLB e page table a 3 livelli.",
          risposta: "HR ≥ 0.87 (≈ 86.67%)",
          spiegazione:
            "Con 3 livelli, un TLB miss richiede 4 accessi RAM: EAT = HR·TRAM + (1−HR)·4·TRAM ⇒ EAT/TRAM = 4 − 3·HR. Imporre EAT ≤ 1.4·TRAM (massimo +40% rispetto a RAM) dà 4 − 3·HR ≤ 1.4 ⇒ 3·HR ≥ 2.6 ⇒ HR ≥ 2.6/3 = 0.8666… ≈ 0.87.",
        },
        {
          domanda:
            "In che modo un allocatore Buddy affronta il problema della frammentazione?",
          risposta:
            "I blocchi liberi possono avere solo dimensioni pari a una potenza di 2, il che riduce il problema della frammentazione esterna",
          spiegazione:
            "Il sistema Buddy suddivide e fonde blocchi di memoria in potenze di due. Questo vincolo semplifica la ricombinazione di blocchi adiacenti e riduce la frammentazione esterna, anche se può causare frammentazione interna quando la richiesta non utilizza tutto il blocco assegnato.",
        },
        {
          domanda:
            "Una free list (di frame liberi) potrebbe essere ordinata, per supportare l'allocazione di frame contigui a un costo lineare",
          risposta:
            "Per indirizzi fisici decrescenti; Per indirizzi fisici crescenti",
          spiegazione:
            "Ordinare la free list per indirizzi fisici, sia in ordine crescente che decrescente, consente di individuare facilmente frame fisicamente adiacenti, riducendo il costo di ricerca di blocchi contigui a O(n). L'ordinamento per dimensione o la mancanza di ordinamento non agevolano questa ricerca.",
        },
        {
          domanda:
            "In un file system con indicizzazione a due livelli (puntatori a 32 bit, blocchi da 4 KB), qual è la dimensione massima di un file?",
          risposta: "4 GiB (4,294,967,296 byte)",
          spiegazione:
            "Ogni blocco indice contiene 4096/4 = 1024 puntatori. Con due livelli si hanno 1024 (primo livello) × 1024 (secondo livello) = 1,048,576 blocchi dati indirizzabili. Moltiplicando per 4096 byte/blocco si ottiene 1,048,576 × 4096 = 4,294,967,296 byte = 4 GiB.",
        },
        {
          domanda:
            "Per un file binario da 9019 KiB, quanti blocchi indice occupa?",
          risposta:
            "4 blocchi indice (3 di secondo livello + 1 di primo livello)",
          spiegazione:
            "Dimensione file: 9019 KiB = 9019 × 1024 = 9,235,456 byte. Blocchi dati necessari: ⌈9,235,456 / 4096⌉ = 2255. Ogni blocco indice di 2° livello punta a 1024 blocchi dati ⇒ ⌈2255 / 1024⌉ = 3 blocchi di 2° livello. Serve 1 blocco di 1° livello che contiene 3 puntatori ai blocchi di 2° livello. Totale indici: 3 + 1 = 4.",
        },
        {
          domanda:
            "Per il file da 9019 KiB, qual è la frammentazione interna dei soli blocchi indice?",
          risposta:
            "7,352 byte (3,268 B nei blocchi di 2° livello + 4,084 B nel blocco di 1° livello)",
          spiegazione:
            "Nei 3 blocchi di 2° livello: 2 sono pieni (2 × 1024 voci), il 3° usa solo 2255 − 2048 = 207 voci ⇒ voci libere = 1024 − 207 = 817 ⇒ 817 × 4 = 3,268 B. Nel blocco di 1° livello si usano 3 voci su 1024 ⇒ (1024 − 3) × 4 = 4,084 B. Somma frammentazione interna indici = 3,268 + 4,084 = 7,352 B.",
        },
        {
          domanda:
            "Il file contiene numeri double (64 bit). Quanti blocchi indice si leggono per accedere ai primi 128K numeri?",
          risposta:
            "2 blocchi indice (1 di primo livello + 1 di secondo livello)",
          spiegazione:
            "128K = 128 × 1024 = 131,072 numeri; ciascuno 8 byte ⇒ 1,048,576 byte. Blocchi dati richiesti: 1,048,576 / 4096 = 256. Questi 256 puntatori risiedono nello stesso blocco di 2° livello (capacità 1024 voci). Per indirizzarli occorre leggere 1 blocco indice di 1° livello (che punta al blocco di 2° livello) + 1 blocco di 2° livello.",
        },
        {
          domanda:
            "L'operazione di apertura di un file (open) può modificare sia la per-process file table che la system-wide?",
          risposta: "Sì",
          spiegazione:
            "La chiamata open inserisce un nuovo entry nella tabella file del processo e, se il file non è già aperto globalmente, può creare o aggiornare l'entry corrispondente nella tabella globale (system-wide open file table).",
        },
        {
          domanda:
            "Il requisito principale per l'implementazione delle directory è l'efficienza nel creare e rimuovere (delete) un file?",
          risposta: "No",
          spiegazione:
            "Le directory sono ottimizzate principalmente per ricerche rapide di nomi e mapping tra nomi e inode o FCB; l'efficienza nella creazione/cancellazione è importante ma non è il requisito principale.",
        },
        {
          domanda: "Una per-process file table è allocata nello spazio kernel?",
          risposta: "Sì",
          spiegazione:
            "In OS e file system tipici, la per-process file table risiede nello spazio kernel per motivi di protezione e gestione sicura delle strutture interne.",
        },
        {
          domanda:
            "Il puntatore alla posizione corrente di lettura/scrittura in un file aperto risiede nel blocco di controllo del file (file control block)?",
          risposta: "No",
          spiegazione:
            "Il puntatore di posizione corrente (offset) è memorizzato nella system-wide open file table o struttura equivalente associata alla sessione di apertura, non nel FCB, che descrive proprietà permanenti del file.",
        },
        {
          domanda:
            "L'accesso sequenziale non può essere simulato dall'accesso casuale (diretto)?",
          risposta: "No",
          spiegazione:
            "L’accesso sequenziale può essere simulato usando accessi casuali, incrementando progressivamente l’offset per leggere o scrivere il file in ordine.",
        },
        {
          domanda:
            "L'accesso casuale (diretto) non può essere implementato tramite formati di allocazione file basati su liste concatenate (ad esempio FAT, lista di blocchi)?",
          risposta: "No",
          spiegazione:
            "Formati come FAT o liste di blocchi possono supportare l’accesso diretto, ma richiedono un attraversamento sequenziale della struttura per raggiungere il blocco desiderato, rendendo l’operazione meno efficiente.",
        },
        {
          domanda:
            "L'accesso casuale (diretto) può essere implementato da tutti i formati di allocazione dei file?",
          risposta: "Sì",
          spiegazione:
            "Tutti i principali formati di allocazione (contigua, indicizzata, a lista concatenata) possono supportare accesso diretto; cambia solo l’efficienza del calcolo del blocco da leggere o scrivere.",
        },
        {
          domanda:
            "L'accesso casuale (diretto) può essere simulato dall'accesso sequenziale?",
          risposta: "Sì",
          spiegazione:
            "Per simulare l’accesso diretto usando operazioni sequenziali, si può scorrere il file in ordine fino a raggiungere la posizione desiderata; è meno efficiente ma possibile.",
        },
        {
          domanda:
            "Sono date due configurazioni RAID: A con 2 dischi in mirroring e B con 4 dischi (striping + mirroring). Tutti i dischi hanno lo stesso MTTF. L'MTTTDL (perdita di dati) di B è superiore all'MTTTDL di A?",
          risposta: "No",
          spiegazione:
            "Con striping + mirroring (RAID 10) e 4 dischi, la probabilità complessiva di perdita dati non è superiore a quella di un semplice mirroring a 2 dischi; anzi, la tolleranza ai guasti è almeno equivalente, se non migliore.",
        },
        {
          domanda:
            "Dati N dischi in configurazione striping, se tutti i dischi hanno un dato MTTF, la probabilità di un guasto diminuisce con l'aumento del valore di N?",
          risposta: "No",
          spiegazione:
            "In striping puro (RAID 0), aumentando N cresce la probabilità che almeno un disco fallisca, quindi la probabilità complessiva di guasto aumenta, non diminuisce.",
        },
        {
          domanda: "Il mirroring include bit di parità?",
          risposta: "No",
          spiegazione:
            "Il mirroring (RAID 1) memorizza copie complete dei dati su dischi diversi, senza usare bit di parità; la parità è tipica di configurazioni come RAID 5 o RAID 6.",
        },
        {
          domanda:
            "Dopo un guasto, l'utilizzo del sistema deve essere interrotto fino al completamento della riparazione?",
          risposta: "No",
          spiegazione:
            "Nelle configurazioni RAID ridondanti, dopo un guasto il sistema può continuare a funzionare in modalità degradata, ricostruendo i dati dal mirroring o dalla parità, senza interruzione completa del servizio.",
        },
      ];

      const eserciziGennaio2025IT = [
        {
          domanda: "L’IPT permette sempre di risparmiare memoria?",
          risposta: "NO",
          spiegazione:
            "Non c'è risparmio nel caso di pochi processi con spazio di indirizzamento piccolo.",
        },
        {
          domanda:
            "Il risparmio di memoria con IPT dipende dalle dimensioni della RAM, dal numero di processi e dal loro spazio di indirizzamento virtuale?",
          risposta: "YES",
          spiegazione:
            "Per motivi simili alla risposta precedente: il risparmio varia in base a questi fattori.",
        },
        {
          domanda:
            "Si risparmia sempre memoria quando lo spazio di indirizzamento di un processo è maggiore della dimensione della RAM?",
          risposta: "NO",
          spiegazione:
            "È un caso in cui IPT può essere più efficiente di PT, ma esistono anche altri scenari, ad esempio molti processi con spazio di indirizzamento minore della RAM ma la somma di tutte le Page Table maggiore della IPT.",
        },
        {
          domanda:
            "Si può risparmiare memoria anche se lo spazio di indirizzamento di ogni processo è inferiore alla dimensione della RAM?",
          risposta: "YES",
          spiegazione: "Perché la IPT è unica per tutti i processi.",
        },
        {
          domanda: "Nella IPT, la chiave di ricerca è la coppia (pid, frame)?",
          risposta: "NO",
          spiegazione:
            "Il frame corrisponde all'indice della tabella, quindi non fa parte della chiave di ricerca.",
        },
        {
          domanda: "Nella IPT, la chiave di ricerca è la coppia (pid, pagina)?",
          risposta: "YES",
          spiegazione:
            "La chiave di ricerca include la pagina e il pid; se si intende solo 'pagina', non è sufficiente.",
        },
        {
          domanda:
            "Per migliorare le prestazioni, si sostituisce la IPT con una tabella di hash?",
          risposta: "NO",
          spiegazione:
            "Sarebbe un'altra soluzione e non un'IPT; non è un miglioramento ma un cambiamento di struttura.",
        },
        {
          domanda:
            "Per migliorare le prestazioni, si aggiunge alla IPT una tabella di hash?",
          risposta: "YES",
          spiegazione:
            "È la tecnica tipicamente usata per migliorare le prestazioni di una IPT.",
        },
        {
          domanda:
            "Un processo ha spazio di indirizzamento virtuale di 48 GB in un sistema a 64 bit con 16 GB di RAM, gestione della memoria paginata (pagine/frame da 4 KB) e 4 GB di RAM riservati al kernel. Confrontare le dimensioni di una tabella delle pagine standard (una per processo) e di una IPT (Inverted Page Table). Il PID richiede 12 bit. Si utilizzano 28 bit per indici di pagina/frame e si allinea ogni cella a 32 o 64 bit. Calcolare: (A) le dimensioni di PT e IPT; (B) lo spazio di indirizzamento virtuale massimo di un processo con la IPT proposta.",
          risposta: "A: PT: 48 MB; IPT: 24 MB; | B: 64 GB",
          spiegazione:
            "Page Table - Numero pagine: 48 GB / 4 KB = 12 milioni di pagine; Bit richiest per ogni entry: 24 bit indice + 4 bit extra → allineamento a 32 bit (4 B), Calcolo dimensione: 12M × 4 B = 48 MB | IP - Ram utente: 16 GB - 4 GB kernel = 12 GB, numero frame: 12 GB / 4 KB = 3 milioni di frame, Bit richiesti: 12 bit PID + 24 bit pagina + 4 bit extra = 40 bit → allineamento a 64 bit (8 B), Calcolo dimensione: 3M × 8 B = 24 MB; Spazio massimo IPT - Limite indici per la IPT proposta è di 24 bit per indice di pagina → massimo 2^24 = 16M pagine, per uno spazio totale di: 16M × 4 KB = 64 GB di spazio virtuale massimo",
        },
        {
          domanda:
            "Dato un disco con blocchi di 8KB e una partizione A con NM blocchi per metadati (inclusa una bitmap) e ND blocchi per dati, sapendo che NM/4 blocchi sono riservati alla bitmap con 1 bit per ciascuno dei ND blocchi, calcolare il rapporto ND/NM.",
          risposta: "ND/NM = 16K",
          spiegazione:
            "La bitmap occupa NM/4 blocchi, cioè NM/4 × 8KB × 8 bit = 16K × NM bit. Ogni bit della bitmap corrisponde a un blocco dati, quindi ND = 16K × NM. Da ciò segue ND/NM = 16K.",
        },
        {
          domanda:
            "Supponendo che la bitmap indichi un rapporto blocchi liberi/usati di 33,33% (1 blocco libero ogni 3 usati), calcolare, in funzione di NM, la dimensione massima possibile per un intervallo contiguo di blocchi liberi nella configurazione più favorevole e in quella meno favorevole.",
          risposta:
            "massima configurazione favorevole: 4K * NM blocchi, massima configurazione sfavorevole: 1 blocco",
          spiegazione:
            "Con un rapporto Nfree/Nused = 1/3, la frazione di blocchi liberi è 0,25 del totale dei blocchi rappresentati dalla bitmap, cioè 0,25 * 16K * NM = 4K * NM blocchi liberi. Nella configurazione più favorevole tutti i blocchi liberi sono contigui formando un intervallo massimo di 4K * NM blocchi. Nella configurazione meno favorevole i blocchi liberi sono isolati e l'intervallo massimo contiguo è di un solo blocco.",
        },
        {
          domanda:
            "È possibile caricare dinamicamente un programma senza che sia necessario il dynamic linking? Il dynamic linking richiede che un programma sia anche caricabile dinamicamente (dynamic loading)?",
          risposta: "Sì, è possibile.",
          spiegazione:
            "Il dynamic linking può essere combinato con il dynamic loading, ma non è obbligatorio. Un programma può essere staticamente linkato e caricato dinamicamente o incrementalmente, ad esempio tramite dynamic loading basato sul programma. Il dynamic loading significa che parti del programma sono caricate in memoria solo quando necessario, mentre il dynamic linking risolve i riferimenti tra moduli a runtime, utile soprattutto per le librerie condivise.",
        },
        {
          domanda:
            "Perché un’Inverted Page Table necessita di una tabella di HASH e perché la soluzione IPT + tabella di HASH è diversa da una soluzione con PT basata solo su tabella di HASH?",
          risposta:
            "Per evitare una ricerca lineare nella IPT, serve una tabella di HASH.",
          spiegazione:
            "Senza una tabella di HASH, la ricerca nella IPT sarebbe lineare e inefficiente. Nella soluzione IPT+HASH, le entry della IPT sono direttamente inserite nelle liste di concatenamento della tabella di HASH, rendendo più efficiente la gestione della memoria rispetto a una tabella di HASH semplice, che richiede allocazioni e deallocazioni classiche ad ogni inserimento o cancellazione.",
        },
        {
          domanda:
            'Una CPU dotata di TLB può contenere entry di più processi simultaneamente o solo per un processo? Il bit "valid" in una entry della TLB è una copia del bit "valid" nella Page Table?',
          risposta:
            "Esistono entrambe le tipologie: TLB che contengono entry di più processi e TLB che contengono solo entry del processo attivo.",
          spiegazione:
            'Le TLB che contengono solo entry del processo attivo richiedono un reset/clean della TLB ad ogni cambio di contesto. Il bit "valid" nella TLB indica se l\'entry è libera o usata, mentre nella Page Table indica se la pagina logica è mappata a un frame fisico.',
        },
      ];

      const eserciziGiugno = [
        {
          domanda:
            "La politica di rimpiazzamento delle pagine basata sul working set è una politica a dimensione fissa?",
          risposta: "NO",
          spiegazione:
            "La dimensione del working set (insieme residente) cambia dinamicamente in base alle pagine accedute nella finestra temporale Delta, quindi non è fissa.",
        },
        {
          domanda:
            "Perché è difficile implementare la politica del working set?",
          risposta: [
            "Perché l'insieme residente va aggiornato anche in assenza di page fault",
            "Perché la tecnica richiede di memorizzare il tempo dell’ultimo accesso per ogni pagina",
          ],
          spiegazione:
            "Non è difficile scegliere un buon Delta: il valore influenza solo le prestazioni. Non è necessario mantenere una lista completa degli accessi, basta l'ultimo accesso. La difficoltà sta nel dover aggiornare il working set anche quando non ci sono page fault, e nel dover tenere traccia del tempo dell'ultimo accesso per ogni pagina.",
        },
        {
          domanda:
            "Considera una strategia LRU basata su pila (stack) con 5 frame. Dato il reference string: 4, 6, 4, 1, 7, 8, 2, 2, 3 (T1), 4, 2 (T2). Rappresenta lo stack al tempo T1 (dopo il riferimento a 3) e T2 (dopo il secondo riferimento a 2).",
          risposta: {
            T1: "3,2,8,7,1",
            T2: "2,4,3,2,8",
          },
          spiegazione:
            "La pila viene aggiornata spostando in cima la pagina più recentemente usata. A T1 la pila contiene: 3,2,8,7,1. Dopo l'accesso alla pagina 4 e poi a 2 (T2), la pila diventa: 2,4,3,2,8.",
        },
        {
          domanda:
            "Due sequenze di riferimento w1 e w2 (di uguale lunghezza) vengono valutate con due algoritmi di rimpiazzamento A1 e A2, con p2 = 2*p1. A1 produce lo stesso numero di page fault (5000) per entrambe le sequenze. A2 produce un numero diverso di fault per w1 e w2, ma la somma è 10000. Se A1 ha una frequenza di page fault del 20% superiore rispetto ad A2, calcola F1 e F2 di A2.",
          risposta: {
            F1_A2: 2500,
            F2_A2: 7500,
          },
          spiegazione:
            "Sappiamo che F(A1) = p1 * (5000 + 2 * 5000) = 15000 * p1. Dato che F(A1) è il 20% in più di F(A2), allora: 1.2 * (x + 2y) = 15000 → x + 2y = 12500. Insieme a x + y = 10000, risolvendo il sistema otteniamo: x = 2500 e y = 7500.",
        },
        {
          domanda:
            "Un file binario di dimensione 23033 KB è memorizzato in un file system con allocazione indicizzata e blocchi di 4KB. Calcolare il numero esatto di blocchi dati e blocchi indice utilizzati, e la frammentazione interna per entrambi.",
          risposta: {
            blocchi_dati: 5759,
            blocchi_indice: 6,
            frammentazione_interna_dati: "3KB",
            frammentazione_interna_indici: "1516B",
          },
          spiegazione:
            "Ogni blocco dati è di 4KB, quindi servono ceil(23033KB / 4KB) = 5759 blocchi dati. L’ultimo blocco dati è riempito solo al 25%, quindi la frammentazione interna nei dati è 0.75 * 4KB = 3KB. Ogni blocco indice può contenere 1023 puntatori (4096 / 1024) a blocchi dati, più uno per collegare il blocco indice successivo. Per contenere 5759 blocchi dati servono ceil(5759 / 1023) = 6 blocchi indice. La frammentazione interna nei blocchi indice è data dagli slot non usati: 6 * 1023 - 5759 = 379 slot inutilizzati → 379 * 4B = 1516B.",
        },
        {
          domanda:
            "Un file di testo di 15300 byte contiene linee di lunghezza variabile, ognuna terminata da ‘\\n’. La lunghezza media è di 50 caratteri (escluso ‘\\n’), e la lunghezza massima è 100. Quante righe contiene il file?",
          risposta: 300,
          spiegazione:
            "La lunghezza media effettiva di ogni riga è 51 byte (50 caratteri + 1 carattere ‘\\n’). Quindi: numero di righe = 15300 / 51 = 300 righe esatte. Non è necessario indicare un intervallo minimo/massimo.",
        },
        {
          domanda:
            "Nel file precedente (B), la presenza di righe di lunghezza variabile influisce sulla strategia di allocazione del file system?",
          risposta: "NO",
          spiegazione:
            "L’allocazione dei blocchi su disco è gestita dal file system ed è indipendente dalla struttura del contenuto del file. Che il file contenga righe fisse o variabili, l’allocazione è fatta a blocchi di dimensione fissa.",
        },
        {
          domanda:
            "Tutti i blocchi allocati contengono lo stesso numero di righe, calcolabile come dimensione del blocco diviso la lunghezza massima della riga?",
          risposta: "NO",
          spiegazione:
            "Il numero di righe per blocco dipende dalla lunghezza reale delle righe, che è variabile. Anche se il massimo è 100, alcune righe possono essere più corte. Inoltre, questa è una questione di livello applicativo: il file system gestisce blocchi di byte, non righe di testo.",
        },
        {
          domanda:
            "La reach del TLB diminuisce quando aumenta la dimensione della pagina?",
          risposta: "NO",
          spiegazione:
            "La reach del TLB, cioè la quantità di memoria virtuale che può essere mappata tramite il TLB, aumenta con l’aumentare della dimensione delle pagine, perché il numero di entry nel TLB resta fisso, ma ciascuna entry copre una porzione maggiore di memoria.",
        },
        {
          domanda:
            "La frammentazione aumenta quando aumenta la dimensione della pagina, perché sono necessarie partizioni contigue più grandi?",
          risposta: "NO",
          spiegazione:
            "La frammentazione interna effettivamente aumenta con pagine più grandi, ma la motivazione indicata è errata: nella paginazione non c'è allocazione contigua, quindi il problema non dipende da partizioni contigue.",
        },
        {
          domanda:
            "Il prepaging è utile solo se la probabilità che una pagina pre-caricata venga realmente usata è superiore all'80%?",
          risposta: "NO",
          spiegazione:
            "Il prepaging è utile quando le pagine pre-caricate hanno un’alta probabilità di essere usate, ma non esiste una soglia fissa del tipo 'superiore all'80%'.",
        },
        {
          domanda:
            "Tutte le strutture dati del kernel richiedono allocazione contigua?",
          risposta: "NO",
          spiegazione:
            "Solo alcune strutture del kernel richiedono allocazione contigua (per efficienza o per vincoli hardware), come ad esempio la tabella delle pagine. Molte altre strutture possono essere allocate in modo non contiguo.",
        },
        {
          domanda: "L’allocatore slab usa solo dimensioni pari a potenze di 2?",
          risposta: "NO",
          spiegazione:
            "L’allocatore buddy utilizza taglie pari a potenze di 2. Lo slab allocator invece è progettato per ridurre la frammentazione e può usare dimensioni arbitrarie basate sugli oggetti richiesti.",
        },
        {
          domanda:
            "Una free list di pagine ha in media una frammentazione interna pari a mezza pagina?",
          risposta: "NO",
          spiegazione:
            "Le free list non contengono dati, ma solo riferimenti a pagine libere. Quindi non introducono frammentazione interna: rappresentano solo spazio disponibile.",
        },
      ];

      const eserciziGennaioInglese = [
        {
          domanda:
            "[EN] Example: What is the main advantage of demand paging in virtual memory systems?",
          risposta:
            "It allows programs to use more memory than physically available, loading pages only when needed.",
          spiegazione:
            "Demand paging improves memory utilization and enables running large programs by loading only the required pages into RAM, reducing memory waste.",
        },
        {
          domanda:
            "[EN] Comparison between standard Page Table and Inverted Page Table (IPT)",
          risposta: "See details below.",
          spiegazione: `
                  <strong>System:</strong><br>
                  Architecture: 64 bit<br>
                  Total RAM: 16GB (Kernel: 4GB, User: 12GB)<br>
                  Page size: 4KB<br>
                  Virtual address space per process: 48GB<br>
                  PID bits: 12<br>
                  Page index bits: 28<br><br>
                  <strong>Advantages of IPT:</strong><br>
                  <ul>
                    <li>"Always saves memory": <span style="color:red;">False</span> – With few processes and small address space, PT can be smaller.</li>
                    <li>"Depends on RAM size, number of processes, and their virtual address space": <span style="color:green;">True</span> – Memory saving with IPT depends on context.</li>
                    <li>"Always saves memory when process address space > RAM size": <span style="color:green;">True</span> – PT grows with virtual space, IPT is fixed size.</li>
                    <li>"Can save memory even if process address space < RAM size": <span style="color:green;">True</span> – IPT is unique for all processes, PTs are many.</li>
                  </ul>
                  <strong>Disadvantages of IPT:</strong><br>
                  <ul>
                    <li>"Search key is (pid,frame)": <span style="color:red;">False</span> – Frame is the index, not the search key.</li>
                    <li>"Search key is (pid,page)": <span style="color:green;">True</span> – IPT is accessed via (pid, page number).</li>
                    <li>"To improve performance, replace IPT with a hash table": <span style="color:red;">False</span> – That is a different approach.</li>
                    <li>"To improve performance, add a hash table to IPT": <span style="color:green;">True</span> – Standard technique to speed up IPT access.</li>
                  </ul>
                  <strong>Calculations:</strong><br>
                  <u>Standard Page Table:</u><br>
                  Number of pages: 12,582,912<br>
                  Cell size: 4B<br>
                  Total size: 48MB<br>
                  <u>IPT:</u><br>
                  Number of frames: 3,145,728<br>
                  Cell size: 8B (PID: 12 bits, Page: 28 bits)<br>
                  Total size: 24MB<br>
                  <strong>Maximum virtual address space with IPT:</strong><br>
                  Page index bits: 28 → Max pages: 268,435,456<br>
                  Page size: 4KB<br>
                  Max virtual space: 1TB<br>
                  Reason: 28 bits = 256M pages × 4KB = 1TB<br>
                  <strong>Conclusions:</strong><br>
                  <ul>
                    <li>Memory advantage: IPT is more compact (24MB vs 48MB)</li>
                    <li>Virtual address space limit: 1TB per process (with 28 page index bits)</li>
                    <li>IPT performance: Slower, improved with hash table</li>
                    <li>PT flexibility: Can support larger virtual spaces if hierarchical</li>
                  </ul>
                `,
        },
        {
          domanda: "[IT] Link/Load, Inverted Page Table (IPT) e TLB (JSON)",
          risposta: "Vedi dettagli sotto.",
          spiegazione: `
                  <strong>Titolo:</strong> Link/Load, Inverted Page Table (IPT) e TLB<br><br>
                  <u>Sezione A</u><br>
                  <strong>1. È possibile caricare dinamicamente un programma senza che sia necessario il dynamic linking?</strong><br>
                  <span style='color:green;'>Risposta: Sì</span><br>
                  <em>Motivazione:</em> Il caricamento dinamico (dynamic loading) consiste nel caricare parti del programma solo quando necessarie. Può essere usato anche con linking statico, ad esempio caricando moduli opzionali in runtime senza doverli linkare dinamicamente.<br><br>
                  <strong>2. Il dynamic linking richiede che un programma sia anche caricabile dinamicamente?</strong><br>
                  <span style='color:red;'>Risposta: No</span><br>
                  <em>Motivazione:</em> Il linking dinamico (dynamic linking) può avvenire anche con moduli già presenti in memoria (come librerie condivise), senza caricare il programma in modo incrementale. Sono due concetti separati e indipendenti.<br><br>
                  <u>Sezione B</u><br>
                  <strong>Perché un'Inverted Page Table necessita di una tabella di hash e in che cosa differisce da una Page Table basata su hash?</strong><br>
                  <ul>
                    <li><strong>PID nella IPT:</strong> Ogni entry della IPT deve contenere il PID per distinguere tra le pagine di processi diversi. Questo non è necessario nella PT classica, perché ogni processo ha la propria tabella delle pagine.</li>
                    <li><strong>Necessità hash:</strong> Una ricerca nella IPT senza hash sarebbe lineare: si deve cercare la coppia (PID, numero di pagina virtuale) per trovare il frame.</li>
                    <li><strong>Differenza hash IPT vs PT hash:</strong> Con la IPT + hash table, le entry della IPT sono referenziate direttamente tramite le liste della hash table (più efficiente), mentre in una PT hash-based si allocano dinamicamente nuove entry, con maggiore overhead di memoria e gestione.</li>
                    <li><strong>Nota:</strong> La IPT è globale per tutto il sistema, mentre le PT (anche se hash-based) sono per singolo processo.</li>
                  </ul>
                  <u>Sezione C</u><br>
                  <strong>1. La TLB può contenere entry di più processi simultaneamente?</strong><br>
                  <span style='color:green;'>Risposta: Sì, ma dipende dall'architettura</span><br>
                  <em>Motivazione:</em> Esistono TLB con campo ASID (Address Space Identifier), che permettono di distinguere tra processi e mantenere entry multiple. Se assente, la TLB è monoprocesso e deve essere azzerata a ogni context switch.<br><br>
                  <strong>2. Il valid bit della TLB è una semplice copia del valid bit della Page Table?</strong><br>
                  <span style='color:red;'>Risposta: No</span><br>
                  <em>Motivazione:</em> Il significato è diverso: nella TLB il 'valid' indica se l'entry è attiva o può essere riutilizzata; nella Page Table indica se la pagina è effettivamente mappata in un frame di memoria fisica.<br>
                `,
        },
        {
          domanda:
            "[IT] Organizzazione di un disco: calcoli e rapporti tra blocchi, bitmap e FCB",
          risposta: "Vedi dettagli sotto.",
          spiegazione: `
                  <strong>Specifiche disco:</strong><br>
                  Dimensione blocco: <strong>8KB</strong><br>
                  Partizione: <strong>A</strong><br>
                  NB: numero totale di blocchi<br>
                  NM: numero blocchi metadati<br>
                  ND: numero blocchi dati<br>
                  Bitmap blocchi: <strong>NM/4</strong><br>
                  Bitmap note: 1 bit per ogni blocco dati<br><br>
                  <strong>Sezione A:</strong><br>
                  <u>Domanda:</u> Calcolare il rapporto ND/NM<br>
                  <u>Calcoli:</u><br>
                  Dimensione bitmap (bit): NM/4 × 8KB × 8 = 16K × NM bit<br>
                  ND = 16K × NM<br>
                  <u>Risultato:</u><br>
                  ND/NM = <strong>16K</strong><br><br>
                  <strong>Sezione B:</strong><br>
                  <u>Domanda:</u> Dimensione massima di un intervallo contiguo di blocchi liberi, in base alla configurazione della bitmap<br>
                  <u>Ipotesi:</u> 1 blocco libero ogni 3 usati (33.33%)<br>
                  <u>Calcoli:</u><br>
                  Nbit totali = 16K × NM<br>
                  Nfree = 0.25 × Nbit totali = 4K × NM<br>
                  <u>Risultato:</u><br>
                  Più favorevole: <strong>4K × NM blocchi liberi contigui</strong><br>
                  Meno favorevole: <strong>1 blocco libero contiguo massimo</strong><br><br>
                  <strong>Sezione C:</strong><br>
                  <u>Domanda:</u> Calcolo di ND, NM, NB e dimensione partizione A, dati FCB da 256B e 16K file massimi<br>
                  <u>Dati:</u><br>
                  Dimensione FCB: 256B<br>
                  FCB per blocco: 32<br>
                  Blocchi FCB: NM/4<br>
                  Max file: 16K<br>
                  <u>Calcoli:</u><br>
                  FCB totali: 32 × NM/4 = 8 × NM<br>
                  Equazione: 8 × NM = 16K ⇒ NM = 2K<br>
                  ND = 16K × NM = 32M<br>
                  NB = ND + NM = 32M + 2K<br>
                  Dimensione bitmap: NM/4 × 8KB = 512 × 8KB = 4MB<br>
                  Dimensione partizione A: (32M + 2K) × 8KB = 256GB + 16MB<br>
                  <u>Risultato:</u><br>
                  NM: <strong>2K blocchi</strong><br>
                  ND: <strong>32M blocchi</strong><br>
                  NB: <strong>32M + 2K blocchi</strong><br>
                  Bitmap: <strong>4MB</strong><br>
                  Dimensione partizione A: <strong>256GB + 16MB</strong><br>
                `,
        },
      ];

      const eserciziSettembre = [
        {
          domanda:
            "In un sistema di memoria virtuale con un grado fisso di multiprogrammazione, il thrashing può verificarsi anche se la somma dei working set di tutti i processi è inferiore alla memoria fisica disponibile, ma l'algoritmo di sostituzione della pagina non è ottimizzato?",
          risposta: "YES",
          spiegazione:
            "Il thrashing può comunque verificarsi se l'algoritmo di sostituzione delle pagine non tiene conto dei working set o causa sostituzioni frequenti e non necessarie. Anche con memoria sufficiente, un cattivo algoritmo può degradare le prestazioni.",
        },
        {
          domanda:
            "Calcola il numero di blocchi su disco necessari per memorizzare un file da 5 MB in un file system con allocazione collegata, blocchi da 4 KB e puntatore di 4 byte in ogni blocco.",
          risposta: "1280 blocchi",
          spiegazione:
            "Dimensione file = 5 MB = 5,242,880 byte. Ogni blocco è di 4 KB (4096 byte) ma 4 byte sono occupati dal puntatore → 4092 byte disponibili per dati. Numero di blocchi = 5,242,880 / 4092 ≈ 1280.",
        },
        {
          domanda:
            "Se la dimensione del puntatore fosse ridotta a 2 byte, quanti blocchi sarebbero necessari e ciò renderebbe lo storage più efficiente?",
          risposta: "1280 blocchi; sì, è più efficiente",
          spiegazione:
            "Con puntatore di 2 byte, ogni blocco ha 4094 byte disponibili per dati. Numero di blocchi = 5,242,880 / 4094 ≈ 1280,63 → arrotondato a 1280. Si risparmia 1 blocco rispetto al caso con puntatore a 4 byte, migliorando leggermente l'efficienza.",
        },
        {
          domanda:
            "Confronta l'overhead introdotto dai puntatori nei due casi come percentuale dello storage totale.",
          risposta: "4-byte pointer: 0,098% — 2-byte pointer: 0,049%",
          spiegazione:
            "Con puntatore a 4 byte: overhead totale = 1282 × 4 = 5128 byte → 5128 / 5,242,880 × 100 ≈ 0,098%. Con puntatore a 2 byte: overhead = 1281 × 2 = 2562 byte → 2562 / 5,242,880 × 100 ≈ 0,049%. L'overhead si dimezza passando a puntatori da 2 byte.",
        },
        {
          domanda:
            "In un sistema con paginazione basata su inverted page table (IPT), è possibile che più pagine virtuali di processi diversi condividano una singola entry della tabella delle pagine senza causare un conflitto nella traduzione degli indirizzi?",
          risposta: "YES",
          spiegazione:
            "L'IPT utilizza una singola entry per ogni frame fisico e include anche l'ID del processo. Quindi, anche se due pagine virtuali diverse condividono un frame, la tabella può distinguerle grazie al PID e non si verifica conflitto.",
        },
        {
          domanda:
            "In un sistema di paginazione a richiesta che utilizza la sostituzione delle pagine locale (a un singolo processo), un processo con frequenza di page fault molto elevata può comunque causare una riduzione della memoria fisica disponibile per altri processi?",
          risposta: "NO",
          spiegazione:
            "La sostituzione locale limita l'uso della memoria fisica da parte del processo alle sue proprie pagine. Anche se il processo ha molti page fault, non può 'rubare' frame ad altri processi, quindi non riduce la memoria disponibile per loro.",
        },
        {
          domanda:
            "Si consideri un sistema a 64 bit con uno spazio di indirizzi virtuale di 2^64 Byte, una dimensione di pagina di 4 KB e 16 GB di memoria fisica. Si supponga che il sistema utilizzi una Inverted Page Table (IPT). Calcolare e spiegare quanto segue:<ol><li>Il numero di bit necessari per il numero di frame fisico.</li><li>Il numero totale di entry nella Inverted Page Table.</li><li>Dato l’indirizzo virtuale <code>0x00007FFFFFFFF000</code>, determinare l’indirizzo fisico se è mappato al frame fisico 1024.</li></ol>",
          risposta: "1) 22 bit, 2) 4M entry, 3) 0x0000000004000000",
          spiegazione: `<strong>1. Numero di bit per frame fisico:</strong><br>La memoria fisica è di 16 GB = 2<sup>34</sup> byte.<br>La dimensione di una pagina è 4 KB = 2<sup>12</sup> byte.<br>Numero di frame fisici = 2<sup>34</sup> / 2<sup>12</sup> = 2<sup>22</sup> = 4M frame.<br>Per identificare ciascun frame servono <strong>22 bit</strong>.<br><br><strong>2. Numero totale di entry nella IPT:</strong><br>L'Inverted Page Table contiene un'entry per ciascun frame fisico.<br>Quindi contiene <strong>2<sup>22</sup> = 4 milioni di entry</strong>.<br><br><strong>3. Traduzione indirizzo virtuale:</strong><br>Indirizzo virtuale: <code>0x00007FFFFFFFF000</code><br>Dimensione pagina = 4 KB = 2<sup>12</sup> → offset = ultimi 12 bit = <code>0x000</code><br>Quindi offset = 0, e il numero di pagina è dato da:<br><code>0x00007FFFFFFFF000 / 0x1000 = 0x00007FFFFFFFF</code> (numero di pagina virtuale)<br>Il frame fisico a cui è mappato è il <strong>1024</strong>-esimo →<br>Indirizzo fisico = <code>1024 * 0x1000 = 0x400000</code><br>Offset = 0 →<br><strong>Indirizzo fisico finale:</strong> <code>0x0000000004000000</code>`,
        },
        {
          domanda:
            "Si consideri un file system che utilizza l'allocazione di tipo <strong>linked</strong>. Il disco è diviso in blocchi di 4 KB, e ogni blocco contiene un puntatore al blocco successivo (4 byte). Un file richiede 5 MB di spazio.<ol><li>Calcolare il numero di blocchi necessari, includendo lo spazio per i puntatori.</li><li>Ricalcolare con puntatori da 2 byte. È più efficiente?</li><li>Confrontare il sovraccarico dei puntatori in entrambi i casi, come percentuale del totale.</li></ol>",
          risposta: `A) 1282 blocchi<br>B) 1281 blocchi, sì, leggermente più efficiente<br>C) Sovraccarico: 5128B (4B), 2562B (2B)`,
          spiegazione: `<strong>A. Calcolo con puntatori da 4 byte:</strong><br>Ogni blocco è di 4096 B, ma 4 B sono riservati al puntatore → 4092 B utili per dati.<br>File = 5 MB = 5 × 1024 × 1024 = 5,242,880 B<br>Numero blocchi = 5,242,880 / 4092 ≈ <strong>1282 blocchi</strong><br><br><strong>B. Calcolo con puntatori da 2 byte:</strong><br>Dati per blocco = 4096 - 2 = 4094 B<br>5,242,880 / 4094 ≈ <strong>1281 blocchi</strong><br>Meno blocchi → meno frammentazione interna → <strong>più efficiente</strong><br><br><strong>C. Sovraccarico in entrambi i casi:</strong><br>- Puntatori da 4 B: 1282 × 4 = <strong>5128 B</strong><br>- Puntatori da 2 B: 1281 × 2 = <strong>2562 B</strong><br>Percentuali:<br>- Caso 1: (5128 / 5,242,880) × 100 ≈ <strong>0.098%</strong><br>- Caso 2: (2562 / 5,242,880) × 100 ≈ <strong>0.049%</strong><br>→ <em>Il sovraccarico si dimezza passando da 4 B a 2 B, anche se in valore assoluto è già molto basso.</em>`,
        },
        {
          domanda:
            "In un sistema con memoria virtuale basata su paginazione a richiesta e DMA, è possibile che si verifichi un page fault durante un trasferimento DMA, causando l'esito negativo del trasferimento se non vengono prese le dovute precauzioni?",
          risposta: "YES",
          spiegazione:
            "Il DMA accede direttamente alla memoria fisica. Se l’indirizzo richiesto non è ancora stato caricato in RAM (page fault), il trasferimento fallisce, a meno che non si usino tecniche come il pinning delle pagine per evitarne lo spostamento.",
        },
        {
          domanda:
            "In un sistema con più dispositivi di I/O e una singola CPU, le operazioni di I/O possono essere eseguite in parallelo se la CPU è occupata nell'esecuzione di un processo?",
          risposta: "YES",
          spiegazione:
            "Le operazioni di I/O possono procedere in parallelo grazie a meccanismi come il DMA o l’I/O asincrono. La CPU può continuare a eseguire altri processi mentre i dispositivi gestiscono autonomamente i trasferimenti.",
        },
        {
          domanda:
            "In un sistema che utilizza I/O basato su interrupt, è possibile che un interrupt venga perso se il controller di interrupt è occupato nell'elaborazione di un altro interrupt e il dispositivo che ha attivato il secondo interrupt non supporta l'accodamento degli interrupt?",
          risposta: "YES",
          spiegazione:
            "Se il controller non è in grado di gestire interrupt concorrenti o accodarli, e il dispositivo non supporta il buffering degli interrupt, un secondo interrupt può essere ignorato mentre il primo è ancora in elaborazione.",
        },
        {
          domanda:
            "Prendere in considerazione un'unità disco rigido (HDD) con le seguenti specifiche:<br>· Dimensione del settore: 512 byte<br>· Numero di tracce per faccia: 5.000<br>· Numero di settori per traccia: 300<br>· Numero di piatti a doppia faccia: 6<br>· Velocità di rotazione del piatto: 7.200 giri/min (giri al minuto)<br><ol><li>Calcolare la velocità di trasferimento dati massima possibile in megabyte al secondo (MB/s), supponendo che sia possibile trasferire una traccia di dati per giro.</li><li>Se il disco subisce un arresto anomalo della testina su un piatto, in che modo ciò influisce sulla capacità totale e sulla disponibilità dei dati supponendo che non siano in atto meccanismi RAID o di backup?</li><li>Se il disco ha un tempo di ricerca medio di 4 ms e deve leggere un file da 1 GB suddiviso in 200 tracce non contigue, calcolare il tempo totale necessario per leggere il file. Includi il tempo per la ricerca, la latenza rotazionale e il trasferimento dei dati. Si supponga che la latenza rotazionale media sia di 4,165 ms e che sia possibile leggere una traccia per giro.</li></ol>",
          risposta: `1) 17.58 MB/s<br>2) Capacità ridotta a 7.87 GB<br>3) Tempo totale ≈ 8.25 s`,
          spiegazione: `<strong>1. Velocità di trasferimento:</strong><br>Ogni traccia contiene 512B × 300 = 150 KB.<br>Velocità di rotazione: 7.200 giri/min = 120 giri/s dunque 1 giro in 1/120 s = 8.33 ms.<br>150 KB × 120 = <strong>18.000 KB/s</strong> = <strong>17.58 MB/s</strong>.<br><br><strong>2. Arresto testina su un piatto:</strong><br>1 piatto = 150 KB × 5.000 tracce = 732.4 MB.<br>Capacità totale iniziale = 8.58 GB.<br>Capacità ridotta = 8.58 GB - 732.4 MB = <strong>7.87 GB</strong>.<br><br><strong>3. Tempo di lettura file 1 GB su 200 tracce:</strong><br>Tempo di ricerca medio = 4 ms.<br>Latenza rotazionale media = 4.165 ms.<br>Tempo per giro = 8.33 ms.<br>Tempo totale = 200 × (4 + 4.165 + 8.33) = 3.299 s.<br>Nota: 1 GB non può stare in sole 200 tracce, servono circa 583 tracce.<br>Tempo totale per 583 tracce = 583 × (4 + 4.165 + 8.33) ≈ <strong>8.25 s</strong>.<br>Se si leggessero solo 200 tracce: <strong>3.3 s</strong>.<br>La stima dipende dalla reale distribuzione del file sulle tracce.`,
        },
        {
          domanda:
            "In un sistema con più dispositivi I/O e una singola CPU, le operazioni di I/O possono avvenire in parallelo se la CPU è occupata a eseguire un processo?",
          risposta: "Sì",
          spiegazione:
            "Le operazioni di I/O possono essere gestite da controller I/O dedicati, permettendo loro di procedere indipendentemente dalla CPU. La CPU può continuare a eseguire processi mentre le operazioni di I/O sono in corso.",
        },
        {
          domanda:
            "In un sistema con memoria virtuale a demand paging e DMA, può verificarsi un page fault durante un trasferimento DMA, causando il fallimento del trasferimento se non si prendono precauzioni?",
          risposta: "Sì",
          spiegazione:
            "Il page fault non è causato direttamente dal trasferimento DMA, poiché il DMA usa indirizzi fisici e quindi memoria fisica contigua. Tuttavia, un page fault può essere generato da codice (dello stesso processo o di altri) in esecuzione in parallelo. Per evitare problemi, le pagine coinvolte nel DMA non devono essere scelte come vittime per la sostituzione: il sistema operativo deve bloccarle in memoria o gestire i page fault in modo da non interrompere il DMA.",
        },
        {
          domanda:
            "In un sistema che utilizza I/O basato su interrupt, è possibile perdere un interrupt se il controller è occupato a elaborarne un altro e il dispositivo che ha generato il secondo interrupt non supporta la messa in coda degli interrupt?",
          risposta: "Sì",
          spiegazione:
            "Se il controller di interrupt è impegnato a gestire un interrupt e il dispositivo che genera un secondo interrupt non supporta la messa in coda, il secondo interrupt può essere perso. Questo accade perché il controller potrebbe non registrare il nuovo interrupt durante l'elaborazione di quello corrente, e senza messa in coda il dispositivo non può trattenere la richiesta fino a quando il controller è libero.",
        },
        {
          domanda:
            "Calcola il massimo tasso di trasferimento dati in MB/s per un HDD con settore da 512 B, 300 settori per traccia, 5000 tracce per superficie, 6 piatti a doppia faccia e velocità di rotazione di 7200 rpm, assumendo che per ogni rivoluzione si possa trasferire una traccia.",
          risposta: "≈17,57 MB/s",
          spiegazione:
            "Capacità traccia = 300 × 512 B = 153.600 B = 0,1465 MB. Tempo per rivoluzione = 60.000 ms / 7200 ≈ 8,33 ms. Velocità = 0,1465 MB / 8,33 ms × 1000 ≈ 17,57 MB/s. Si assume che le tracce su un cilindro non vengano lette/scritte in parallelo.",
        },
        {
          domanda:
            "Se un piatto dell'HDD subisce un head crash, come cambia la capacità e la disponibilità dei dati senza RAID o backup?",
          risposta:
            "Capacità ridotta a 7,68 GB, dati persi sul piatto danneggiato",
          spiegazione:
            "Ogni piatto ha due superfici. Perdita di un piatto = perdita di 2 superfici su 12 totali → capacità ridotta di 2/12. Capacità nuova = 9,216 GB × (10/12) = 7,68 GB. I dati sul piatto guasto non sono recuperabili senza backup.",
        },
        {
          domanda:
            "Calcola il tempo totale per leggere un file da 1 GB diviso in 200 tracce non contigue, dato che il tempo medio di seek è 4 ms, la latenza rotazionale media è 4,165 ms e si può leggere una traccia per rivoluzione.",
          risposta: "≈59,8 secondi",
          spiegazione:
            "Trasferimento: 1 GB = 1.073.741.824 B. Capacità per traccia = 153.600 B. Tempo di trasferimento totale = (1.073.741.824 / 153.600) × 8,33 ms ≈ 58,21 s. Seek totale = 200 × 4 ms = 0,8 s. Latenza totale = 200 × 4,165 ms = 0,833 s. Tempo totale ≈ 58,21 + 0,8 + 0,833 = 59,8 s. Nota: il calcolo ignora che 200 tracce non possono contenere 1 GB, come segnalato nel testo.",
        },
      ];

      const eserciziLuglio2016 = [
        {
          domanda:
            "Dato un file di 80MB su un file system da 200GB, con blocchi da 4KB e puntatori/indici da 32 bit, quanti blocchi sono necessari per organizzarlo con linked list allocation, FAT e indexed allocation (non iNode)?",
          risposta:
            "Linked list: 20501 blocchi dati; FAT: 20480 blocchi dati; Indexed allocation: 20480 blocchi dati + 21 blocchi indice.",
          spiegazione:
            "Linked list allocation: 80MB / (4KB - 4B) = 20501 blocchi dati, nessun blocco indice. FAT: 80MB / 4KB = 20K = 20480 blocchi dati, nessun blocco indice. Indexed allocation: 20480 blocchi dati; ogni blocco indice contiene 1K indici (4KB/4B), quindi servono 20 blocchi di secondo livello più 1 di primo livello, per un totale di 21 blocchi indice.",
        },
      ];

      function renderEsercizi(esercizi) {
        const eserciziList = document.getElementById("esercizi-list");
        eserciziList.innerHTML = "";
        esercizi.forEach((ex, idx) => {
          const card = document.createElement("div");
          card.className = "esercizio-card";
          let rispostaHtml = "";
          if (typeof ex.risposta === "object" && !Array.isArray(ex.risposta)) {
            rispostaHtml = Object.entries(ex.risposta)
              .map(([k, v]) => `<div><strong>${k}:</strong> ${v}</div>`)
              .join("");
          } else if (Array.isArray(ex.risposta)) {
            rispostaHtml = ex.risposta.map((r) => `<div>${r}</div>`).join("");
          } else {
            rispostaHtml = `Risposta: ${ex.risposta}`;
          }

          let spiegazioneHtml = "";
          if (typeof ex.spiegazione === "object" && ex.spiegazione !== null) {
            spiegazioneHtml = renderSpiegazioneObj(ex.spiegazione);
          } else {
            spiegazioneHtml = ex.spiegazione;
          }

          card.innerHTML = `
                  <div class="esercizio-header" tabindex="0" role="button" aria-expanded="false">
                    <span>ESERCIZIO ${idx + 1}</span>
                    <span class="arrow">&#9654;</span>
                  </div>
                  <div class="esercizio-content">
                    <div class="domanda">${ex.domanda}</div>
                    <div class="risposta">${rispostaHtml}</div>
                    <div class="spiegazione">${spiegazioneHtml}</div>
                  </div>
                `;
          const header = card.querySelector(".esercizio-header");
          const content = card.querySelector(".esercizio-content");
          const arrow = card.querySelector(".arrow");
          content.style.display = "none";
          header.addEventListener("click", function () {
            const expanded = content.style.display === "block";
            content.style.display = expanded ? "none" : "block";
            arrow.innerHTML = expanded ? "&#9654;" : "&#9660;";
            header.setAttribute("aria-expanded", !expanded);
          });
          header.addEventListener("keypress", function (e) {
            if (e.key === "Enter" || e.key === " ") {
              header.click();
            }
          });
          eserciziList.appendChild(card);
        });
      }

      function renderSpiegazioneObj(obj) {
        if (typeof obj !== "object" || obj === null) return obj;
        let html = '<ul style="margin-left:1em">';
        for (const [k, v] of Object.entries(obj)) {
          html += `<li><strong>${k}:</strong> `;
          if (typeof v === "object" && v !== null) {
            html += renderSpiegazioneObj(v);
          } else {
            html += v;
          }
          html += "</li>";
        }
        html += "</ul>";
        return html;
      }

      const schedaSelect = document.getElementById("scheda-select");
      function updateScheda() {
        if (schedaSelect.value === "giugno-2024") {
          renderEsercizi(eserciziGiugno);
        } else if (schedaSelect.value === "giugno-2025") {
          renderEsercizi(eserciziGiugno2025);
        } else if (schedaSelect.value === "settembre-2024") {
          renderEsercizi(eserciziSettembre);
        } else if (schedaSelect.value === "gennaio-inglese") {
          renderEsercizi(eserciziGennaioInglese);
        } else if (schedaSelect.value === "gennaio-2025-it") {
          renderEsercizi(eserciziGennaio2025IT);
        } else if (schedaSelect.value === "luglio-2016") {
          renderEsercizi(eserciziLuglio2016);
        }
      }
      schedaSelect.addEventListener("change", updateScheda);

      renderEsercizi(eserciziGiugno);
    </script>
  </body>
</html>
